#
# ContractiliPy (contractili.py) - A python script for processing EHT contractile data
#
# By George McMullen
#
# When studying the ability of engineered heart tissue (EHT) to contract and 
# relax, data is generated by performing motion capture analysis of physical
# specimens. As such, data captured in two dimensions (X and Y coordinates)
# over time. Phyiscal speciments can vary in a multitude of ways, including
# but not limited to angles, stability, physical properties of the media
# holding the EHT, and possible inconsistencies unintentionally caused my
# manual handling. This makes it difficult to analyze the results of EHT
# contractility studies at scale and in an auditable and repeatable manner.
#
# ContractiliPy's goal is enable high-volume, error-resistant analysis of
# EHT contractility data, by largely automatiting the tasks associated with
# calculating contractile force, velocity, and other parameters. It also
# provides a visual output of the analyzed waveforms, enabling quick and
# easy verification that the appropriate parameters were used and correct
# results were obtained.
#


#
#
# Imported libraries (part 1)
#
# Only the basic libraries required by command line arguments are imported first
# in order to speed up execution and error checking when an incorrect argument
# has been used. See "Imported libraries (part 2)" for the rest.
#
#
import argparse
import os
import string


#
#
# Functions
#
#

#
# Argument validation
#
def positiveInteger(string):
    value = int(string)
    if value < 0:
       msg = "%r is not a positive integer" % string
       raise argparse.ArgumentTypeError(msg)
    return value

def positiveFloat(string):
    value = float(string)
    if value < 0:
       msg = "%r is not a positive float" % string
       raise argparse.ArgumentTypeError(msg)
    return value

def floatInRange(string):
    value = float(string)
    if value < 0 or value > 1:
       msg = "%r is not a float between 0.0 and 1.0" % string
       raise argparse.ArgumentTypeError(msg)
    return value

def existingFile(string):
    if os.path.isfile(string) != True:
       msg = "%r file not found" % string
       raise argparse.ArgumentTypeError(msg)
    return string

def existingDir(string):
    if os.path.isdir(string) != True:
       msg = "%r output directory not found" % string
       raise argparse.ArgumentTypeError(msg)
    return string


#
#
# Internal analysis functions
#
#

#
# getStartPeakEnd(dataArray)
#
# This is just a wrapper function for peak detection. Other peak detection functions
# can be put in place here without modifying the rest of the code.
#
def getStartPeakEnd(dataArray):
    minima        = numpy.array([], dtype=numpy.integer)
    maxima        = numpy.array([], dtype=numpy.integer)
    reverseMinima = numpy.array([], dtype=numpy.integer)

    # First we get the regular max and min using peak detection
    #peaksMax, peaksMin = peakdetect(dataArray, lookahead=peakDetectLookAhead, delta=peakDetectDelta)
    peaksMax, peaksMin = peakdetect(dataArray, lookahead=peakDetectLookAhead)
    #peaksMax, peaksMin = peakdetect(dataArray)
    maxima = numpy.array([p[0] for p in peaksMax])
    minima = numpy.array([p[0] for p in peaksMin])

    # If the first minima is before the first maxima, then we need to shift it over
    # so we are always start with a max peak, as we will be looking for decay information.
    while len(minima) > 0 and len(maxima) > 0 and minima[0] < maxima[0]:
        minima = minima[1:]

    # We need the reverseMinima, maxima, and minima to be the same size to we don't get any out of bounds errors
    smallestAmount = min([len(maxima), len(minima)])

    while (len(maxima) > smallestAmount):
        maxima = maxima[:-1]

    while (len(minima) > smallestAmount):
        minima = minima[:-1]

    if printVerbose == True:
       print "getStartPeakEnd - maxima: {0}".format(maxima)
       print "getStartPeakEnd - minima: {0}".format(minima)

    if len(maxima) > 0 and len(minima) > 0: 
        newDelta = abs(numpy.average(numpy.abs(dataArray[minima]-dataArray[maxima])) / 10)

        if printVerbose == True:
           print "getStartPeakEnd - ewDelta: {0}".format(newDelta)

        if newDelta and ~numpy.isnan(newDelta):
            #peaksMax, peaksMin = peakdetect(dataArray, lookahead=peakDetectLookAhead, delta=newDelta)
            peaksMax, peaksMin = peakdetect(dataArray, lookahead=peakDetectLookAhead)
            maxima = numpy.array([p[0] for p in peaksMax])
            minima = numpy.array([p[0] for p in peaksMin])

            # In order to get the beginning of the peak, we reverse the wave form, and then capture the minima
            #peaksMax, peaksMin = peakdetect(dataArray[::-1], lookahead=peakDetectLookAhead, delta=newDelta)
            peaksMax, peaksMin = peakdetect(dataArray[::-1], lookahead=peakDetectLookAhead)
            reverseMinima = numpy.array([p[0] for p in peaksMin])
            reverseMinima = (len(dataArray)-1)-reverseMinima
            reverseMinima = reverseMinima[::-1]
        else:
            # In order to get the beginning of the peak, we reverse the wave form, and then capture the minima
            peaksMax, peaksMin = peakdetect(dataArray[::-1], lookahead=peakDetectLookAhead)
            reverseMinima = numpy.array([p[0] for p in peaksMin])
            reverseMinima = (len(dataArray)-1)-reverseMinima
            reverseMinima = reverseMinima[::-1]
      

    # Ideally, the returned data should be in the order of start, peak, and end
    # Thus, we need to remove data points that do not conform to that pattern in the beginning and end.
    # First, we check to make sure that the first maxima comes after the first reverseMinima
    while len(reverseMinima) > 0 and len(maxima) > 0 and reverseMinima[0] > maxima[0]:
        maxima = maxima[1:]
    
    # If the first minima is before the first maxima, then we need to shift it over
    # so we are always start with a max peak, as we will be looking for decay information.
    while len(minima) > 0 and len(maxima) > 0 and minima[0] < maxima[0]:
        minima = minima[1:]

    # We need the reverseMinima, maxima, and minima to be the same size to we don't get any out of bounds errors
    smallestAmount = min([len(reverseMinima), len(maxima), len(minima)])

    while (len(reverseMinima) > smallestAmount):
        reverseMinima = reverseMinima[:-1]

    while (len(maxima) > smallestAmount):
        maxima = maxima[:-1]

    while (len(minima) > smallestAmount):
        minima = minima[:-1]

    fixedMinima = getFixedPeakEnd(reverseMinima, maxima, minima, dataArray)

    return [fixedMinima, reverseMinima, maxima, minima]

#
# getFixedPeakEnd(reverseMinima, maxima, minima, dataArray)
#
# Sometimes the peak detection algorithm will choose the lowest point in a wavelet
# as the minima, rather than th point at which the waveform flattens out. This function
# will traverse the wavelets from each peak to minima, and choose the first point where the
# waveform is at its flattest.
#
def getFixedPeakEnd(reverseMinima, maxima, minima, dataArray):
    fixedMinima = numpy.array([], dtype=numpy.integer)

    if len(maxima) < 2:
       return fixedMinima

    segmentSize = 15
    detectionThreshold = 1.1

    # Here we check to make sure the segment size is small enough to reasonably fit the decay portion of the wavelet
    numPeaks= len(maxima)
    peakRange=maxima[-1]-maxima[0]
    dataPointsPerPeak=peakRange/numPeaks
    if (dataPointsPerPeak/4 < segmentSize):
      segmentSize=dataPointsPerPeak/4
    
    for j in range(len(maxima)):
      #if (minima[j] - maxima[j]) > ((maxima[j] - reverseMinima[j]) * detectionThreshold):
        minimumAngle=90
        minimumAnglePosition=maxima[j]
        if (minima[j]+segmentSize+1 < len(dataArray)):
          for k in range(maxima[j],minima[j]+1):
            currentSegmentSize=segmentSize
            # As we get closer to the minimum, we shorten the segement size
            if (minima[j])-k < currentSegmentSize:
               currentSegmentSize=(minima[j])-k
            currentAngle = numpy.rad2deg(numpy.arctan2(abs(dataArray[k+currentSegmentSize] - dataArray[k]), currentSegmentSize))
            if (currentAngle < minimumAngle):
              minimumAngle=currentAngle
              minimumAnglePosition=k
        else:
          minimumAnglePosition=minima[j]
        fixedMinima = numpy.append(fixedMinima, minimumAnglePosition)
      #else:
      #  fixedMinima = numpy.append(fixedMinima, minima[j])
    return fixedMinima

#
# getIndexAtAmplitude(dataArray, amplitude, normalize)
#
# This function will return the first index where a signal will reach a given
# amplitude during its decay phase. If normalization is enabled, the signal will be
# normalized by subtracting its lowest value from the entire signal.
# When analyzing calcium fluorescence decay data, amplitude offsets (also referred
# to Calcium Time to Decay or CTD offsets) are used for a variety of reasons,
# including reduction of error with noisy signals.
# Keep in mind that CTD25 means decay to 75% power, and vice versa. CTD75 means decay to 25% power.
# https://www.sciencedirect.com/science/article/pii/S105687191630034X
#
def getIndexAtAmplitude(dataArray, amplitude, normalize):
    if len(dataArray) == 0:
       return 0

    # We make a copy of it because we may normalize the data
    dataArrayCopy = copy.copy(dataArray)

    if (normalize):
       dataArrayCopy = numpy.nan_to_num(dataArrayCopy) - min(numpy.nan_to_num(dataArrayCopy))

    searchValue = max(dataArrayCopy) * amplitude

    closestValueIndex=int((numpy.abs(dataArrayCopy-searchValue)).argmin())

    # Different method which basically just looks for the first point at which the value is less or equal to the amplitude
    #closestValueIndex=0
    #for k in range(len(dataArrayCopy)):
    #  if dataArrayCopy[k] < searchValue:
    #    closestValueIndex=k
    #    break

    return closestValueIndex

#
# getIndicesAtAmplitude(dataArray, minima, maxima, amplitude, normalize)
#
# This function will return the indices where a signal will reach a given
# amplitude during its decay phase.
#
def getIndicesAtAmplitude(dataArray, minima, maxima, amplitude, normalize):
    indices = numpy.ndarray(shape=(0), dtype=int);
    for j in range(len(minima)):
        start = int(maxima[j])
        end = int(minima[j])

        indexAtAmplitude = getIndexAtAmplitude(dataArray[start:end+1], amplitude, normalize)

        indices = numpy.append(indices, int(start+indexAtAmplitude))

    if len(indices) == 0:
      indices = [0]

    return indices

def chooseWaveforms(dataArray):
    if printVerbose == True:
       print "chooseWaveforms - workSheetMaxColumn: {0}".format(workSheetMaxColumn)

    columnsToProcess = [0,1]
    if 2 > workSheetMaxColumn-1:
       return 0

    averageDifference0=0
    averageDifference1=0
    
    fixedMinima, reverseMinima, maxima, minima  = getStartPeakEnd(dataArray[:,0])
    if len(maxima) > 0 and len(minima) > 0:
       if printVerbose == True:
          print "chooseWaveforms - maxima 0: {0}".format(dataArray[maxima,0])
          print "chooseWaveforms - minima 0: {0}".format(dataArray[minima,0])

       # Make sure arrays are same length by truncating them
       maxima=maxima[:len(minima)]
       minima=minima[:len(maxima)]
       averageDifference0 = (dataArray[maxima,0] - dataArray[minima,0]).mean()

       if printVerbose == True:
          print "chooseWaveforms - averageDifference0: {0}".format(averageDifference0)

    if printVerbose == True:
       print "chooseWaveforms - averageDifference0: {0}".format(averageDifference0)

    fixedMinima, reverseMinima, maxima, minima  = getStartPeakEnd(dataArray[:,1])
    if len(maxima) > 0 and len(minima) > 0:
       if printVerbose == True:
          print "chooseWaveforms - maxima 1: {0}".format(dataArray[maxima,1])
          print "chooseWaveforms - minima 1: {0}".format(dataArray[minima,1])

       # Make sure arrays are same length by truncating them
       maxima=maxima[:len(minima)]
       minima=minima[:len(maxima)]
       averageDifference1 = (dataArray[maxima,1] - dataArray[minima,1]).mean()
       if printVerbose == True:
          print "chooseWaveforms - averageDifference1: {0}".format(averageDifference1)

    if printVerbose == True:
       print "chooseWaveforms - averageDifference1: {0}".format(averageDifference1)

    if abs(averageDifference0) > abs(averageDifference1):
       if printVerbose == True:
          print "chooseWaveforms - First waveform chosen"
       return 0
    else:
       if printVerbose == True:
          print "chooseWaveforms - Second waveform chosen"
       return 1

def alignWaveforms(dataArray):
    columnsToProcess = range(dataArray.shape[1])

    for i in columnsToProcess:
        # We take the data for the current column, calculate ratios and choose the proper ratio
        ratioArray=dataArray[:,i]

        if printVerbose == True:
           print "alignWaveforms - len(ratioArray): {0}".format(len(ratioArray))

        # Get the peaks of the waveform as minima and maxima positions
        fixedMinima, reverseMinima, maxima, minima  = getStartPeakEnd(ratioArray)

        if len(maxima) > 1 and len(minima) > 1:
           averageSignal=ratioArray[maxima[0]:maxima[1]].mean() - ratioArray[minima[0]]
           signalRange = ratioArray[maxima[0]] - ratioArray[minima[0]]
           if averageSignal / signalRange > .50:
              dataArray[:,i]=dataArray[:,i]*-1
        
    return dataArray

#
#
# Argument parsing
#
#

argumentParser = argparse.ArgumentParser(prog='calci.py', description='Process ratiometric calcium fluorescence decay data.')

argumentParser.add_argument('inputfile', metavar='filename', type=existingFile, help='input filename to process')

argumentParser.add_argument('-O', '--outputdir', type=existingDir, default='.', help='output files to a directory')

argumentParser.add_argument('--sheetname', help='process only a specific worksheet by name (use quotes)')
argumentParser.add_argument('--sheetnum', type=positiveInteger, help='process only a specific worksheet by number')
argumentParser.add_argument('--column', type=positiveInteger, help='process only a specific cell line column of data (typically 1-10)')

argumentParser.add_argument('--elasticity', type=positiveFloat, default=1.7E6, help='elasticity modulus (default=1.7E6 in Pa/Pascals')
argumentParser.add_argument('--radius',     type=positiveFloat, default=.5E-3, help='radius of the posts (default=.5E-3 -> 0.5mm)')
argumentParser.add_argument('--distance',   type=positiveFloat, default=10E-3, help='distance between two posts (default=10E-3 -> 10mm)')

argumentParser.add_argument('--lookahead', type=positiveInteger, default=20, help='peak detection look-ahead parameter (default=20)')
argumentParser.add_argument('--delta',     type=positiveFloat, default=0.0,  help='peak detection delta parameter (default=0)')

argumentParser.add_argument('--show', action='store_true', help='show the graph (with matplotlib)')

argumentParser.add_argument('--verbose', action='store_true', help='print values as they are calculated')

#
#
# Variable initialization
#
#

commandArguments = argumentParser.parse_args()

# inputFileName: Name of the file to process
inputFileName = commandArguments.inputfile

# outputDirectory: The location where output files will be stored
outputDirectory = commandArguments.outputdir

# inputFileNameNoExt: The file's name without any extension
inputFileNameNoExt = os.path.basename(inputFileName).replace(".xlsx","")
inputFileNameNoExt = inputFileNameNoExt.replace(".xls","")
inputFileNameNoExt = inputFileNameNoExt.replace(".csv","")

# outputCSVFileName: The name of the output CSV file
outputCSVFileName = os.path.join(outputDirectory,inputFileNameNoExt+'_Processed.csv')

worksheetToProcess = commandArguments.sheetname
worksheetNumToProcess = commandArguments.sheetnum
if worksheetToProcess is not None and worksheetNumToProcess is not None:
   print "error: argument --sheetname cannot be used at the same time as --sheetnum"
   quit(-1)

# columnToProcess: A specific column to process (depends on worksheetToProcess / worksheetNumToProcess)
columnToProcess = None
if commandArguments.column is not None:
   if worksheetToProcess is not None or worksheetNumToProcess is not None:
      columnToProcess = commandArguments.column
   else:
      print "error: argument --column requires either argument --sheetname or --sheetnum"
      quit(-1)

# Mathematical constants for contractile force calculation
paramElasticity = commandArguments.elasticity # Pa - Pascals (elasticity)
paramRadius     = commandArguments.radius     # m - .5 millimeters (radius of the posts)
paramDistance   = commandArguments.distance   # m - 10 millimeters (distance between two posts)

peakDetectLookAhead = commandArguments.lookahead
peakDetectDelta = commandArguments.delta

# showGraph: Use matplotlib to display the graphs
showGraph = commandArguments.show

# printVerbose: Print out values as they are calculated
printVerbose = commandArguments.verbose

# capitalLetters: All capital letters, which will be used to get the cells from an Excel File
capitalLetters = string.ascii_uppercase

#
#
# Imported libraries part 2
#
# Some libraries, like matplotlib, seem to execute code when getting imported.
# So saving this step for at least after the command line arguments are parsed.
#
import math
import copy
import re
import openpyxl
from openpyxl import load_workbook         # pip install openpyxl
from openpyxl.cell.cell import ILLEGAL_CHARACTERS_RE
import csv
import numpy as numpy
from analytic_wfm import peakdetect        # pip install analytic-wfm
import matplotlib.pyplot as pyplot         # pip install matplotlib
import matplotlib.gridspec as gridspec


#
#
# Main Program
#
#

#
# Load the inputFileName as an Excel file, even if it is a CSV.
# This is not the most elegant method for using CSV and XLS, as it will
# import a CSV file into an Excel object in memory. This is done to keep
# compatibility with the original code, which expected an Excel file.
# This may get converted into a Pandas routine in the future.
#
excelFile = openpyxl.Workbook()
if inputFileName.endswith(('.csv')):
   #
   # Conversion of CSV to XLS
   # https://stackoverflow.com/questions/12976378/openpyxl-convert-csv-to-excel
   #
   workSheet = excelFile.active

   with open(inputFileName) as csvInputFile:
        csvReader = csv.reader(csvInputFile, delimiter=',')
        skippedLines=0
        for row in csvReader:
            # The software adds an additional header row to the CSV file, which we need to remove
            if skippedLines >= 1:
               # For all the columns in each row, replace any illegal characters
               # https://stackoverflow.com/questions/21619230/expected-string-or-buffer-in-re-sub
               workSheet.append([ILLEGAL_CHARACTERS_RE.sub(r'',column) for column in row])
            skippedLines = skippedLines + 1
else:
   excelFile = load_workbook(filename = inputFileName)

allWorkSheetNames = excelFile.sheetnames

# If we have specified a worksheet, make sure it can be found
if worksheetToProcess:
   if allWorkSheetNames.index(worksheetToProcess):
      allWorkSheetNames=[worksheetToProcess]
   else:
      print "error: argument --sheetname worksheet "+worksheetToProcess+" does not exist"
      quit(-1)
elif worksheetNumToProcess is not None:
   if worksheetNumToProcess < len(allWorkSheetNames):
      allWorkSheetNames=[allWorkSheetNames[worksheetNumToProcess]]
   else:
      print "error: argument --sheetnum worksheet "+worksheetNumToProcess+" does not exist"
      quit(-1)

#
# Open the CSV for writing and write the header
#
outputCSVFile = open(outputCSVFileName, 'w')
outputCSVFile.write('Sheet,')
outputCSVFile.write('Cell Line Name,')
outputCSVFile.write('Cell Line #,')
outputCSVFile.write('Average Contraction Distance,')
outputCSVFile.write('Average Contraction Distance XY,')
outputCSVFile.write('Contraction Distance Std Deviation,')
outputCSVFile.write('Contraction Distance XY Std Deviation,')
outputCSVFile.write('Contractile Force (mN),')
outputCSVFile.write('Contractile Force XY (mN),')
outputCSVFile.write('Contraction Time,')
outputCSVFile.write('Contraction Velocity,')
outputCSVFile.write('Relaxation Time,')
outputCSVFile.write('Relaxation Velocity,')
outputCSVFile.write('BPM,')
outputCSVFile.write('Beat Length,')
outputCSVFile.write('Baseline Difference,')
outputCSVFile.write('\n')

#
# Loop through the worksheets in the given Excel file and process them
#
for workSheetName in allWorkSheetNames:
    # Load the Excel work sheet
    # Deprecated function get_sheet_by_name. Use wb[sheetname]
    #workSheet = excelFile.get_sheet_by_name(workSheetName)
    workSheet = excelFile[workSheetName]

    print 'Processing: '+inputFileName+' - '+workSheetName

    # Sometimes we get additional columns with notes in them. That will crash the application.
    # So we manually limit to 16 columns (value of 15 with 0 indexing)
    workSheetMaxColumn = workSheet.max_column

    # If we don't have enough columns in the sheet, then skip it
    if (workSheetMaxColumn < 2):
        continue

    # Create array for the data. The typical sheet in the Excel file has
    # one header row and five columns of additional informaion like time.
    # It may also have up to ten individual columns of data.
    dataArray = numpy.ndarray(shape=(workSheet.max_row-1, workSheetMaxColumn-1))

    # Create an array that will contain the column headers
    columnHeaders = []

    # Create an array for the time signatures of each row in the work sheet.
    timeArray = numpy.ndarray(shape=(workSheet.max_row-1, 1))

    # Fill the data arrays with data from the current work sheet
    for i in range(1, workSheetMaxColumn):
        for j in range(2,workSheet.max_row+1):
            if workSheet[capitalLetters[i] + str(j)].value is not None:
               dataArray[j-2, i-1] = workSheet[capitalLetters[i] + str(j)].value

    # Fill the data arrays with data from the current work sheet
    for i in range(1,workSheetMaxColumn):
        columnHeaders.append(workSheet[capitalLetters[i] + str(1)].value)

    # Fill the time array with data from the current work sheet
    for j in range(2,workSheet.max_row+1):
        timeArray[j-2] = workSheet[capitalLetters[0] + str(j)].value

    # We need to make sure that there is an even number of rows or the script will fail when choosing a ratio with two differently sized arrays.
    if len(timeArray) % 2 != 0:
      dataArray=dataArray[:-1,:]
      timeArray=timeArray[:-1]

    timeArray = timeArray.flatten()      

    #
    # Configure the graph
    #

    # Close all figures as a precaution
    pyplot.close('all')

    # Starts a new figure
    if showGraph == True:
       figure = pyplot.figure()
       titleFontSize = 8
    else:
       figure = pyplot.figure(figsize=(19.20,10.80))
       titleFontSize = 10

    if len(allWorkSheetNames) > 1:
        pyplot.suptitle(inputFileName+' - '+workSheetName)
    else:
        pyplot.suptitle(inputFileName)

    dataArray = alignWaveforms(dataArray)
    chosenWaveforms = chooseWaveforms(dataArray)

    if columnToProcess is None:
       columnsToProcess = range(dataArray.shape[1])
    else:
       if columnToProcess < workSheetMaxColumn-1:
          columnsToProcess = [columnToProcess]
       else:
          columnsToProcess = range(dataArray.shape[1])

    #
    # Setup the graph's grid according to the columns to process
    #
    if len(columnsToProcess) == 1:
       # Create a "grid" of just one row and column
       currentGridSpec = gridspec.GridSpec(1,1, width_ratios=[1, 3, 3])
    else:
       currentGridSpec = gridspec.GridSpec(int(math.ceil(len(columnsToProcess)/2.0)), 2, width_ratios=[3, 1])

    currentGridPosition=0

    #
    # The maximum peaks to plot
    #
    maxToPlot = 0

    # Loop through each of the newly calculated columns
    for i in columnsToProcess[chosenWaveforms::2]:
        # We take the data for the current column, calculate ratios and choose the proper ratio
        ratioArray=dataArray[:,i]
        
        if printVerbose == True:
           print "len(ratioArray): {0}".format(len(ratioArray))

        pair=i+1
        if i % 2 != 0:
           pair=i-1

        # Get the peaks of the waveform as minima and maxima positions
        fixedMinima, reverseMinima, maxima, minima  = getStartPeakEnd(ratioArray)

        analysisStartPoints = getIndicesAtAmplitude(ratioArray, maxima, reverseMinima, 0.0, True)
        analysisEndPoints   = getIndicesAtAmplitude(ratioArray, fixedMinima, maxima, 0.0, True)

        if printVerbose == True:
           print "analysisStartPoints: {0}".format(analysisStartPoints)
           print "analysisEndPoints: {0}".format(analysisEndPoints)

        #
        # Plotting of Time Graph
        #

        # Add a new chart to the grid
        chartSubPlot = figure.add_subplot(currentGridSpec[currentGridPosition])
        currentGridPosition = currentGridPosition + 1

        pyplot.title("Column "+str(i+1)+" (Time)", fontsize=titleFontSize)

        # Chosen 340/380nm ratio waveform
        chartSubPlot.plot(timeArray, ratioArray, 'm')

        numPlotted = 0
        # Peak maximum data points as yellow dots
        for maximum in maxima:
            if maxToPlot == 0 or numPlotted < maxToPlot:
              numPlotted = numPlotted + 1
              chartSubPlot.plot(timeArray[maximum], ratioArray[maximum], 'yo')

        numPlotted = 0
        # Peak minimum data points as red dots
        for minimum in reverseMinima:
            if maxToPlot == 0 or numPlotted < maxToPlot:
              numPlotted = numPlotted + 1
              chartSubPlot.plot(timeArray[minimum], ratioArray[minimum], 'ro')

        numPlotted = 0
        # Peak minimum data points as blue dots
        for minimum in fixedMinima:
            if maxToPlot == 0 or numPlotted < maxToPlot:
              numPlotted = numPlotted + 1
              chartSubPlot.plot(timeArray[minimum], ratioArray[minimum], 'bo')

        numPlotted = 0
        # Analysis start data points as green lines
        for plotPoint in analysisStartPoints:
            if maxToPlot == 0 or numPlotted < maxToPlot:
              numPlotted = numPlotted + 1
              chartSubPlot.plot(timeArray[plotPoint], ratioArray[plotPoint], 'g_')

        numPlotted = 0
        # Analysis end data points as green lines
        for plotPoint in analysisEndPoints:
            if maxToPlot == 0 or numPlotted < maxToPlot:
              numPlotted = numPlotted + 1
              chartSubPlot.plot(timeArray[plotPoint], ratioArray[plotPoint], 'g_')


        #
        # Plotting of XY Graph
        #

        # Add a new chart to the grid
        chartSubPlot = figure.add_subplot(currentGridSpec[currentGridPosition])
        currentGridPosition = currentGridPosition + 1

        pyplot.title("Column "+str(i+1)+" (XY)", fontsize=titleFontSize)

        # Chosen waveform
        chartSubPlot.plot(dataArray[:,pair], ratioArray[:], 'm')

        numPlotted = 0
        # Peak maximum data points as yellow dots
        for maximum in maxima:
            if maxToPlot == 0 or numPlotted < maxToPlot:
              chartSubPlot.plot(dataArray[maximum,pair], ratioArray[maximum], 'yo')
              numPlotted = numPlotted + 1

        numPlotted = 0
        # Peak minimum data points as red dots
        for minimum in reverseMinima:
            if maxToPlot == 0 or numPlotted < maxToPlot:
              chartSubPlot.plot(dataArray[minimum,pair], ratioArray[minimum], 'ro')
              numPlotted = numPlotted + 1

        numPlotted = 0
        # Peak minimum data points as red dots
        for minimum in fixedMinima:
            if maxToPlot == 0 or numPlotted < maxToPlot:
              chartSubPlot.plot(dataArray[minimum,pair], ratioArray[minimum], 'bo')
              numPlotted = numPlotted + 1

        # Calculating metrics
        distance = numpy.array([])
        distanceXY = numpy.array([])
        contractionTime = numpy.array([])
        for j in range(len(reverseMinima)):
            distance = numpy.append(distance, abs(ratioArray[maxima[j]]-ratioArray[analysisStartPoints[j]]))
            distanceXY = numpy.append(distanceXY, math.hypot(abs(ratioArray[maxima[j]] - ratioArray[analysisStartPoints[j]]), abs(dataArray[maxima[j],pair] - dataArray[analysisStartPoints[j],pair])))
            contractionTime = numpy.append(contractionTime, abs(timeArray[maxima[j]]-timeArray[analysisStartPoints[j]]))

        averageDistance    = 0
        averageDistanceXY  = 0
        stdDevDistance     = 0
        stdDevDistanceXY   = 0
        contractileForce   = 0
        contractileForceXY = 0

        if len(distance) > 0:
           averageDistance    = numpy.average(distance)
           averageDistanceXY  = numpy.average(distanceXY)
           
           stdDevDistance     = numpy.std(distance)
           stdDevDistanceXY   = numpy.std(distanceXY)
           
           contractileForce   = 10**3 * paramElasticity * 3 * math.pi * paramRadius**4 * (averageDistance   * 10**-6) / (4 * paramDistance**3);
           contractileForceXY = 10**3 * paramElasticity * 3 * math.pi * paramRadius**4 * (averageDistanceXY * 10**-6) / (4 * paramDistance**3);
        
           averageContractionTime = numpy.average(contractionTime)
        
        totalTime = 0
        bpm       = 0
        if len(maxima) > 0:
            totalTime = timeArray[maxima[-1]] - timeArray[maxima[0]]

            if totalTime > 0:
               bpm = 60 * ((len(maxima)-1) / totalTime)

            beatLength = abs(timeArray[analysisEndPoints] - timeArray[analysisStartPoints]).mean()
            contractionTime = abs(timeArray[maxima] - timeArray[analysisStartPoints]).mean()
            relaxationTime = abs(timeArray[analysisEndPoints] - timeArray[maxima]).mean()

            contractionVelocity=0
            if not numpy.any((abs(timeArray[maxima] - timeArray[analysisStartPoints]) == 0)):
               contractionVelocity = (abs(ratioArray[maxima] - ratioArray[analysisStartPoints]) / abs(timeArray[maxima] - timeArray[analysisStartPoints])).mean()
        
            relaxationVelocity=0
            if not numpy.any((abs(timeArray[analysisEndPoints] - timeArray[maxima]) == 0)):
               relaxationVelocity  = (abs(ratioArray[analysisEndPoints] - ratioArray[maxima]) / abs(timeArray[analysisEndPoints] - timeArray[maxima])).mean()

            baselineDiffernce = (ratioArray[analysisEndPoints] - ratioArray[analysisStartPoints]).mean()

        #
        # Output of data to CSV file
        #
        outputCSVFile.write(workSheetName + ', ')
        outputCSVFile.write(columnHeaders[i] + ', ')
        outputCSVFile.write(str(i+1) + ', ')
        outputCSVFile.write(str(averageDistance) + ', ')
        outputCSVFile.write(str(averageDistanceXY) + ', ')
        outputCSVFile.write(str(stdDevDistance) + ', ')
        outputCSVFile.write(str(stdDevDistanceXY) + ', ')
        outputCSVFile.write(str(contractileForce) + ', ')
        outputCSVFile.write(str(contractileForceXY) + ', ')
        outputCSVFile.write(str(contractionTime) + ', ')
        outputCSVFile.write(str(contractionVelocity) + ', ')
        outputCSVFile.write(str(relaxationTime) + ', ')
        outputCSVFile.write(str(relaxationVelocity) + ', ')
        outputCSVFile.write(str(bpm) + ', ')
        outputCSVFile.write(str(beatLength) + ', ')
        outputCSVFile.write(str(baselineDiffernce) + ', ')
        outputCSVFile.write('\n')

    #
    # Finished processing worksheet
    #

    # Create a new PDF file for each work sheet, which will show the plotted graphs
    outputPDFFileName = os.path.join(outputDirectory,inputFileNameNoExt + '.pdf')
    if len(allWorkSheetNames) > 1:
       outputPDFFileName = os.path.join(outputDirectory,inputFileNameNoExt + '_' + workSheetName + '.pdf')

    # Improve the layout of the grid
    currentGridSpec.tight_layout(figure, rect=[0, 0.03, 1, 0.95], h_pad=0, w_pad=0)

    # Output the plot as a PDF file
    pyplot.savefig(outputPDFFileName, dpi=1200)

    # If we want to view the image generated, uncomment the below file
    if showGraph:
       pyplot.show()

    # Make sure all figures are closed
    pyplot.close('all')

outputCSVFile.close()
